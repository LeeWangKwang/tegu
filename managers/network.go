// vi: sw=4 ts=4:

/*

	Mnemonic:	network
	Abstract:	Manages everything associated with a network. This module contains a 
				goroutine which should be invoked from the tegu main and is responsible
				for managing the network graph and responding to requests for information about
				the network graph. As a part of the collection of functions here, there is also 
				a tickler which causes the network graph to be rebuilt on a regular basis. 

				The network manager goroutine listens to a channel for requests such as finding
				and reserving a path between two hosts, and generating a json representation 
				of the network graph for outside consumption.

				TODO: need to look at purging links/vlinks so they don't bloat if the network changes 

	Date:		24 November 2013
	Author:		E. Scott Daniels

	Mods:		19 Jan 2014 - Added support for host-any reservations.
				11 Feb 2014 - Support for queues on links rather than just blanket obligations per link. 
				21 Mar 2014 - Added noop support to allow main to hold off driving checkpoint 
							loading until after the driver here has been entered and thus we've built
							the first graph.
				03 Apr 2014 - Support for endpoints on the path.
				05 May 2014 - Added support for merging gateways into the host list when not using floodlight.
				18 May 2014 - Changes to allow cross tenant reservations.
*/

package managers

import (
	//"bufio"
	//"encoding/json"
	//"flag"
	"fmt"
	//"io/ioutil"
	//"html"
	//"net/http"
	"os"
	"strings"
	//"time"

	"forge.research.att.com/gopkgs/bleater"
	"forge.research.att.com/gopkgs/clike"
	"forge.research.att.com/gopkgs/ipc"
	"forge.research.att.com/tegu"
	"forge.research.att.com/tegu/gizmos"
	
)

// --------------------------------------------------------------------------------------

	// this probably should be network rather than Network as it's used only internally

/*
	Defines everything we need to know about a network. 
*/
type Network struct {				
	switches	map[string]*gizmos.Switch	// symtable of switches
	hosts		map[string]*gizmos.Host		// references to host by either mac, ipv4 or ipv6 'names'
	links		map[string]*gizmos.Link		// table of links allows for update without resetting allotments
	vlinks		map[string]*gizmos.Link		// table of virtual links (links between ports on the same switch)
	vm2ip		map[string]*string			// maps vm names and vm IDs to IP addresses (generated by ostack and sent on channel)
	ip2vm		map[string]*string			// reverse -- makes generating complete host listings faster
	ip2mac		map[string]*string			// IP to mac	Tegu-lite
	ip2vmid		map[string]*string			// ip to vm-id translation	Tegu-lite
	vmid2phost	map[string]*string			// vmid to physical host name	Tegu-lite
	vmid2ip		map[string]*string			// vmid to ip address	Tegu-lite
	mac2phost	map[string]*string			// mac to phost map generated from OVS agent data (needed to include gateways in graph)
	gwmap		map[string]*string			// mac to ip map for the gateways	(needed to include gateways in graph)
	ip2fip		map[string]*string			// tenant/ip to floating ip address translation
	fip2ip		map[string]*string			// floating ip address to tenant/ip translation
}

type host_pair struct {
	h1	*string
	h2	*string	
	fip	*string			// floating IP address needed for this segment
}


// ------------ private -------------------------------------------------------------------------------------

/*
	constructor
*/
func mk_network( mk_links bool ) ( n *Network ) {
	n = &Network { }
	n.switches = make( map[string]*gizmos.Switch, 20 )		// initial sizes aren't limits, but might help save space
	n.hosts = make( map[string]*gizmos.Host, 2048 )

	if mk_links {
		n.links = make( map[string]*gizmos.Link, 2048 )		// must maintain a list of links so when we rebuild we preserve obligations
		n.vlinks = make( map[string]*gizmos.Link, 2048 )
	}

	return
}

/*
	Tegu-lite
	Using the various vm2 and ip2 maps, build the host array as though it came from floodlight.
*/
func (n *Network) build_hlist( ) ( hlist []gizmos.FL_host_json ) {

	i := 0
	if n != nil && n.ip2mac != nil {								// first time round we might not have any data
		gw_count := 0	
		if n.gwmap != nil {	
			gw_count = len( n.gwmap )
		}
		hlist = make( []gizmos.FL_host_json, len( n.ip2mac ) + gw_count )

		for ip, mac := range n.ip2mac {				// add in regular VMs
			vmid := n.ip2vmid[ip]
			if vmid != nil {						// skip if we don't find a vmid
				net_sheep.Baa( 2, "adding host: [%d] mac=%s ip=%s phost=%s", i, *mac, ip, *(n.vmid2phost[*vmid]) )
				hlist[i] = gizmos.FL_mk_host( ip, "", *mac, *(n.vmid2phost[*vmid]), -128 ) 				// use phys host as switch name and -128 as port
				i++
			}
		}

		if n.gwmap != nil {						// add in the gateways which are not reported by openstack
			if n.mac2phost != nil && len( n.mac2phost ) > 0 {
				for mac, ip := range n.gwmap {
					if n.mac2phost[mac] == nil {
						net_sheep.Baa( 1, "WRN:  build_hlist: unable to find mac in gw list: mac=%s  ip=%s", mac, *ip )
					} else {
						if ip != nil {
							net_sheep.Baa( 2, "adding gateway: [%d] mac=%s ip=%s phost=%s", i, mac, *ip, *(n.mac2phost[mac]) )
							hlist[i] = gizmos.FL_mk_host( *ip, "", mac, *(n.mac2phost[mac]), -128 ) 		// use phys host collected from OVS as switch
							i++
						} else {
							net_sheep.Baa( 1, "WRN:  build_hlist: ip was nil for mac: %s", mac )
						}
					}
				}
			} else {
				net_sheep.Baa( 1, "WRN: no phost2mac map -- agent likely not returend sp2uuid list" )
			}
		} else {
			net_sheep.Baa( 1, "WRN: no gateway map" )
		}

		hlist = hlist[0:i]
	} else {
		hlist = make( []gizmos.FL_host_json,  1 )			// must have empty list to return if net is nil
	}

	return
}

/*
	Tegu-lite
	Takes a set of strings of the form <hostname><space><mac> and adds them to the mac2phost table
	This is needed to map gateway hosts to physical hosts since openstack does not return the gateways
	with the same info as it does VMs
*/
func (n *Network) update_mac2phost( list []string ) {
	if n.mac2phost == nil {
		n.mac2phost = make( map[string]*string )
	}

	for i := range list {
		toks := strings.Split( list[i], " " )
		dup_str := toks[0]
		n.mac2phost[toks[1]] = &dup_str
	}

	net_sheep.Baa( 1, "mac2phost map updated; has %d elements (list had %d elements)", len( n.mac2phost ), len( list ) )
}

/*
	Build the ip2vm map from the vm2ip map which is a map of IP addresses to what we hope is the VM
	name.  The vm2ip map contains both VM IDs and the names the user assigned to the VM. We'll guess
	at getting the name from the map.

	TODO: we need to change vm2ip to be struct with two maps rather than putting IDs and names into the same map
*/
func (n *Network) build_ip2vm( ) ( i2v map[string]*string ) {

	i2v = make( map[string]*string )
	
	for k, v := range n.vm2ip {
		if len( k ) < 36 || strings.Index( k, "/" ) > 0  || i2v[*v] == nil {		// IDs seem to be 36, but we'll save something regardless and miss if user went wild with long name and we hit it second
			dup_str := k							// 'dup' the string so we don't reference the string associated with the other map
			i2v[*v] = &dup_str
			net_sheep.Baa( 2, "build_ip2vm %s --> %s %d", k, *v, *i2v[*v], len( k ) )
		} else {
			net_sheep.Baa( 2, "build_ip2vm skipped:  cur value: %s --> %s %d", k, *v, *i2v[*v], len( k ) )
		}
	}

	net_sheep.Baa( 2, "built ip2vm map: %d entires", len( i2v ) )
	return
}

/*
	Accepts a list (string) of queue data information segments (swid/port,res-id,queue,min,max,pri), splits
	the list based on spaces and adds each information segment to the queue map.  If ep_only is true, 
	then we drop all middle link queues (priority-in priority-out).

	(Supports gen_queue_map and probably not useful for anything else)
*/
func qlist2map( qmap map[string]int, qlist *string, ep_only bool ) {
	qdata := strings.Split( *qlist, " " )		// split the list into tokens

	if ep_only {
		for i := range qdata  {
			if qdata[i] != ""  &&  strings.Index( qdata[i], "priority-" ) < 0 {
				qmap[qdata[i]] = 1;
			}
		}
	} else {
		for i := range qdata {
			if qdata[i] != "" {
				qmap[qdata[i]] = 1;
			}
		}
	}
}

/*
	Traverses all known links and generates a switch queue map based on the queues set for 
	the time indicated by the timestamp passed in (ts). 

	If ep_only is set to true, then queues only for endpoints are generated. 

	TODO:  this needs to return the map, not an array (fqmgr needs to change to accept the map)
*/
func (n *Network) gen_queue_map( ts int64, ep_only bool ) ( qmap []string, err error ) {
	err = nil									// at the moment we always succeed
	seen := make( map[string]int, 100 )			// prevent dups which occur because of double links

	for _, link := range n.links {					// for each link in the graph
		s := link.Queues2str( ts )
		qlist2map( seen, &s, ep_only )						// add these to the map
	}

	for _, link := range n.vlinks {					// and do the same for vlinks
		s := link.Queues2str( ts )
		qlist2map( seen, &s, ep_only )						// add these to the map
	}

	qmap = make( []string, len( seen ) )
	i := 0
	for data := range seen {
		qmap[i] = data
		i++
	}
	net_sheep.Baa( 1, "gen_queue_map: added %d queue tokens to the list (len=%d)", i, len( qmap ) )
	
	return
}

/*
	Returns the ip address associated with the name. The name may indeed be 
	an IP address which we'll look up in the hosts table to verify first. 
	If it's not an ip, then we'll search the vm2ip table for it. 
*/
func (n *Network) name2ip( hname *string ) (ip *string, err error) {
	ip = nil
	err = nil

	if n.hosts[*hname] != nil {					// we have a host by 'name', then 'name' must be an ip address
		ip = hname
	} else {
		ip = n.vm2ip[*hname]					// it's not an ip, try to translate it as either a VM name or VM ID
		if ip != nil {							// the name translates, see if it's in the known net
			if n.hosts[*ip] == nil {			// ip isn't in floodlight scope, return nil
				err = fmt.Errorf( "host unknown: %s maps to an IP, but IP not known to SDNC: %s", *hname, *ip )
				ip = nil
			}
		} else {
			err = fmt.Errorf( "host unknown: %s could not be mapped to an IP address", *hname )
			//net_sheep.Baa( 1, "unable to map name/ID to an IP: %s", *hname )						// caller should bleat
		}
	}

	return
}

/*
	Given two switch names see if we can find an existing link in the src->dest direction
	if lnk is passed in, that is passed through to Mk_link() to cause lnk's obligation to be
	'bound' to the link that is created here. 

	If the link between src-sw and dst-sw is not there, one is created and added to the map.

	We use this to reference the links from the previously created graph so as to preserve obligations.
	(TODO: it would make sense to vet the obligations to ensure that they can still be met should
	a switch depart from the network.)
*/
func (n *Network) find_link( ssw string, dsw string, capacity int64, lnk ...*gizmos.Link ) (l *gizmos.Link) {

	id := fmt.Sprintf( "%s-%s", ssw, dsw )
	l = n.links[id]
	if l != nil {
		if lnk != nil {										// dont assume that the links shared the same allotment previously though they probably do
			l.Set_allotment( lnk[0].Get_allotment( ) )
		}
		return
	}

	net_sheep.Baa( 3, "making link: %s", id )
	if lnk == nil {
		l = gizmos.Mk_link( &ssw, &dsw, capacity );	
	} else {
		l = gizmos.Mk_link( &ssw, &dsw, capacity, lnk[0] );	
	}
	n.links[id] = l
	return
}

/*
	Looks for a virtual link on the switch given between ports 1 and 2.
	Returns the existing link, or makes a new one if this is the first.
	New vlinks are stashed into the vlink hash.

	We also create a virtual link on the endpoint between the switch and 
	the host. In this situation there is only one port (p2 expected to be 
	negative) and the id is thus just sw.port. 
*/
func (n Network) find_vlink( sw string, p1 int, p2 int ) ( l *gizmos.Link ) {
	var(
		id string
	)

	if p2 < 0 {
		id = fmt.Sprintf( "%s.%d", sw, p1 )
	} else {
		id = fmt.Sprintf( "%s.%d.%d", sw, p1, p2 )
	}

	l = n.vlinks[id]
	if l == nil {
		l = gizmos.Mk_vlink( &sw, p1, p2, int64( 10 * ONE_GIG ) )
		l.Set_ports( p1, p2 )
		n.vlinks[id] = l
	}

	return
}

/*
	Build a new graph of the network.
	Host is the name/ip:port of the host where floodlight is running.
	Old-net is the reference net that we'll attempt to find existing links in.
	Max_capacity is the generic (default) max capacity for each link.

	Tegu-lite:  sdnhost might be a file which contains a static graph, in json form,
	describing the physical network. The string is assumed to be a filename if it 
	does _not_ contain a ':'. 
	
*/
func build( old_net *Network, flhost *string, max_capacity int64 ) (n *Network) {
	var (
		ssw		*gizmos.Switch
		dsw		*gizmos.Switch
		lnk		*gizmos.Link
		ip4		string
		ip6		string
		links	[]gizmos.FL_link_json			// list of links from floodlight or simulated floodlight source
		hlist	[]gizmos.FL_host_json			// list of hosts from floodlight or built from vm maps if not using fl
		err		error
	)

	n = nil

	if strings.Index( *flhost, ":" ) >= 0  {
		links = gizmos.FL_links( flhost )					// request the current set of links from floodlight
		hlist = gizmos.FL_hosts( flhost )					// get a current host list from floodlight
	} else {
		hlist = old_net.build_hlist()						// simulate output from floodlight by building the host list from openstack maps
		links, err = gizmos.Read_json_links( *flhost )
		if err != nil {
			net_sheep.Baa( 0, "ERR: unable to read static links from %s: %s", *flhost, err )
			links = nil										// kicks us out later, but must at least create an empty network first
		}
	}


	n = mk_network( old_net == nil )			// new network, need links only if it's the first network
	if old_net == nil {
		old_net = n								// prevents an if around every try to find an existing link.
	} else {
		n.links = old_net.links;				// might it be wiser to copy this rather than reference and update the 'live' copy?
		n.vlinks = old_net.vlinks;
	}

	if links == nil {
		return
	}
	if hlist == nil {
		return
	}

	for i := range links {							// parse all links returned from the controller
		if links[i].Capacity <= 0 {
			links[i].Capacity = max_capacity			// default if it didn't come from the source
		}

		ssw = n.switches[links[i].Src_switch]; 
		if ssw == nil {
			ssw = gizmos.Mk_switch( &links[i].Src_switch )
			n.switches[links[i].Src_switch] = ssw
		}

		dsw = n.switches[links[i].Dst_switch]; 
		if dsw == nil {
			dsw = gizmos.Mk_switch( &links[i].Dst_switch )
			n.switches[links[i].Dst_switch] = dsw
		}

		//lnk = old_net.find_link( links[i].Src_switch, links[i].Dst_switch, max_capacity )		// omitting the link causes reuse of the link if it existed so that obligations are kept
		lnk = old_net.find_link( links[i].Src_switch, links[i].Dst_switch, links[i].Capacity )		// omitting the link causes reuse of the link if it existed so that obligations are kept
		lnk.Set_forward( dsw )
		lnk.Set_backward( ssw )
		lnk.Set_port( 1, links[i].Src_port )		// port on src to dest
		lnk.Set_port( 2, links[i].Dst_port )		// port on dest to src
		ssw.Add_link( lnk )

		lnk = old_net.find_link( links[i].Dst_switch, links[i].Src_switch, links[i].Capacity, lnk )	// including the link causes its obligation to be shared in this direction
		lnk.Set_forward( ssw )
		lnk.Set_backward( dsw )
		lnk.Set_port( 1, links[i].Dst_port )		// port on dest to src
		lnk.Set_port( 2, links[i].Src_port )		// port on src to dest
		dsw.Add_link( lnk )
		net_sheep.Baa( 3, "build: addlink: src [%d] %s %s", i, links[i].Src_switch, n.switches[links[i].Src_switch].To_json() )
		net_sheep.Baa( 3, "build: addlink: dst [%d] %s %s", i, links[i].Dst_switch, n.switches[links[i].Dst_switch].To_json() )
	}

	for i := range hlist {			// parse the unpacked json; structs are very dependent on the floodlight output; TODO: change FL_host to return a generic map
		if len( hlist[i].Mac )  > 0  && len( hlist[i].AttachmentPoint ) > 0 {		// switches come back in the list; if there are no attachment points we assume it's a switch & drop
			if len( hlist[i].Ipv4 ) > 0 {
				ip4 = hlist[i].Ipv4[0]; 		//TODO: we need to associated all ips with the host; for now just the first
			} else {
				ip4 = ""
			}
			if len( hlist[i].Ipv6 ) > 0 {
				ip6 = hlist[i].Ipv6[0]; 
			} else {
				ip6 = ""
			}

			h := gizmos.Mk_host( hlist[i].Mac[0], ip4, ip6 )

			for j := range hlist[i].AttachmentPoint {
				h.Add_switch( n.switches[hlist[i].AttachmentPoint[j].SwitchDPID], hlist[i].AttachmentPoint[j].Port )
				ssw = n.switches[hlist[i].AttachmentPoint[j].SwitchDPID]
				if ssw != nil {							// it should always be known, but no chances
					ssw.Add_host( &hlist[i].Mac[0], hlist[i].AttachmentPoint[j].Port )	// allows switch to provide has_host() method
					net_sheep.Baa( 3, "saving host %s in switch : %s port: %d", hlist[i].Mac[0], hlist[i].AttachmentPoint[j].SwitchDPID, hlist[i].AttachmentPoint[j].Port )
				}
			}

			n.hosts[hlist[i].Mac[0]] = h			// reference by mac and IP addresses (when there)
			net_sheep.Baa( 2, "build: saving host ip4=%s as mac: %s", ip4, hlist[i].Mac[0] )
			if ip4 != "" {
				n.hosts[ip4] = h
			}
			if ip6 != "" {
				n.hosts[ip6] = h
			}
		} else {
			net_sheep.Baa( 2, "skipping host in list (i=%d) attachement points=%d", len( hlist[i].Mac ) )
		}
	}

	return
}

/*
	Given a tenant id, find the associated gateway.  Returns the whole tenant/ip string. 

	TODO: return list if multiple gateways
	TODO: improve performance by maintaining a tid->gw map
*/
func (n *Network) gateway4tid( tid string ) ( *string ) {
	for _, ip := range n.gwmap {				// mac to ip, so we have to look at each value
		toks := strings.SplitN( *ip, "/", 2 )
		if toks[0] == tid {
			return ip
		}
	}

	return nil
}

// -------------------- path finding ------------------------------------------------------------------------------------------------------


/*
	Look at tid/h1 and tid/h2 and split them into two disjoint path endpoints, tid/gw,h1 and tid/gw,h2, if
	the tenant ids for the hosts differ.  This will allow for reservations between tenant VMs that are both
	known to Tegu.  If the endpoints are in different tenants, then we require each to have a floating point
	IP address that is known to us.
*/
func (n *Network) find_endpoints( h1ip *string, h2ip *string ) ( pair_list []host_pair ) {
	if strings.Index( *h1ip, "/" ) < 0 {					// no tenant id in the name we have to assume in the same realm
		pair_list = make( []host_pair, 1 )
		pair_list[0].h1 = h1ip
		pair_list[0].h2 = h2ip
		return
	}

	toks := strings.SplitN( *h1ip, "/", 2 )			// suss out tenant ids
	t1 := toks[0]

	toks = strings.SplitN( *h2ip, "/", 2 )
	t2 := toks[0]

	if t1 == t2 {									// same tenant, just one pair to deal with
		pair_list = make( []host_pair, 1 )
		pair_list[0].h1 = h1ip
		pair_list[0].h2 = h2ip
		return
	}

	f1 := n.ip2fip[*h1ip]
	f2 := n.ip2fip[*h2ip]
	if f1 == nil {
		net_sheep.Baa( 1, "find_endpoints: unable to map host to floating ip: %s", *h1ip )
		return
	}

	if f2 == nil {
		net_sheep.Baa( 1, "find_endpoints: unable to map host to floating ip: %s", *h2ip )
		return
	}

	g1 := n.gateway4tid( t1 )						// map tenant id to gateway which become the second endpoint
	g2 := n.gateway4tid( t2 )

	pair_list = make( []host_pair, 2 )				// return a h1->g1 and h2->g2 pair set
	pair_list[0].h1 = h1ip
	pair_list[0].h2 = g1
	pair_list[0].fip = f2							// destination fip for h1->h2

	pair_list[1].h1 = g2							// order is important to ensure bandwith in/out limits if different
	pair_list[1].h2 = h2ip
	pair_list[1].fip = f1							// destination fip for h1<-h2

	return
}


/*
	Find a set of connected switches that can be used as a path beteeen 
	hosts 1 and 2 (given by name; mac or ip).  Further, all links between from and the final switch must be able to 
	support the additional capacity indicated by inc_cap during the time window between
	commence and conclude (unix timestamps).

	If the network is 'split' a host may appear to be attached to multiple switches; one with a real connection and 
	the others are edge switches were we see an 'entry' point for the host from the portion of the network that we
	cannot visualise.  We must attempt to find a path between h1 using all of it's attached switches, and thus the 
	return is an array of paths rather than a single path.


	h1nm and h2nm are likely going to be ip addresses as the main function translates any names that would have
	come in from the requestor.  

	Extip is an external IP address that will need to be associated with the flow-mods and thus needs to be 
	added to any path we generate.

	DEPRECATED: if the second host is "0.0.0.0", then we will return a path list containing every link we know about :)
*/
func (n *Network) find_path( h1nm *string, h2nm *string, commence int64, conclude int64, inc_cap int64, extip *string ) ( pcount int, path_list []*gizmos.Path ) {
	var (
		path	*gizmos.Path
		ssw 	*gizmos.Switch		// starting switch
		tsw 	*gizmos.Switch; 		// target's linked switch
		h1		*gizmos.Host
		h2		*gizmos.Host
		lnk		*gizmos.Link
		plidx	int = 0
		swidx	int = 0		// index into host's switch list
	)

	h1 = n.hosts[*h1nm]
	if h1 == nil {
		path_list = nil
		net_sheep.Baa( 1,  "find-path: cannot find host(1) in network -- not reported by SDNC? %s\n", *h1nm )
		return
	}
	h1nm = h1.Get_mac()			// must have the host's mac as our flowmods are at that level

	h2 = n.hosts[*h2nm]					// do the same for the second host
	if h2 == nil {
		path_list = nil
		net_sheep.Baa( 1,  "find-path: cannot find host(2) in network -- not reported by the SDNC? %s\n", *h2nm )
		return
	}
	h2nm = h2.Get_mac()

	if h1nm == nil || h2nm == nil {			// this has never happened, but be parinoid
		pcount = 0
		path_list = nil
		net_sheep.Baa( 0, "CRI: find-path: internal error: either 1hnm or h2nm was nil after get mac" )
		return
	}

	path_list = make( []*gizmos.Path, len( n.links ) )		// we cannot have more in our path than the number of links (needs to be changed as this isn't good in the long run)
	pcount = 0

	for {									// we'll break after we've looked at all of the connection points for h1 
		if plidx >= len( path_list ) {
			net_sheep.Baa( 0,  "CRI: find-path: internal error -- unable to find a path between hosts, loops in the graph? Edges exceeded number of total links." )
			return
		}

		ssw, _ = h1.Get_switch_port( swidx )				// get next switch that lists h1 as attached; we'll work 'out' from it toward h2
		swidx++
		if ssw == nil {
			pcount = plidx
			if pcount <= 0 || swidx == 0 {
				net_sheep.Baa( 1, "find-path: early exit? no switch port returned for h1 (%s) at index %d", *h1nm, swidx )
			}
			path_list = path_list[0:pcount]					// slice it down to size
			return
		}

		if ssw.Has_host( h1nm )  &&  ssw.Has_host( h2nm ) {			// if both hosts are on the same switch, there's no path if they both have the same port
			p1 := h1.Get_port( ssw )
			p2 := h2.Get_port( ssw )
			if p1 < 0 || p1 != p2 {									// when ports differ we'll create/find the vlink between them	(in Tegu-lite port == -128 is legit and will dup)
				lnk = n.find_vlink( *(ssw.Get_id()), p1, p2 )
				if lnk.Has_capacity( commence, conclude, inc_cap ) {		// room for the reservation
					lnk.Add_lbp( *h1nm )
					net_sheep.Baa( 1, "path[%d]: found target on same switch, different ports: %s  %d, %d", plidx, ssw.To_str( ), h1.Get_port( ssw ), h2.Get_port( ssw ) )
					path = gizmos.Mk_path( h1, h2 )							// empty path
					path.Set_extip( extip )
					path.Add_switch( ssw )
					path.Add_link( lnk )
	
					path_list[plidx] = path
					plidx++
				} else {
					net_sheep.Baa( 1, "path[%d]: hosts on same switch, virtual link cannot support bandwidth increase of %d", inc_cap )
				}
	
			}  else {					// debugging only
				net_sheep.Baa( 2,  "find-path: path[%d]: found target (%s) on same switch with same port: %s  %d, %d", plidx, *h2nm, ssw.To_str( ), p1, p2 )
				net_sheep.Baa( 2,  "find-path: host1-json= %s", h1.To_json( ) )
				net_sheep.Baa( 2,  "find-path: host2-json= %s", h2.To_json( ) )
			}
			
		} else {						// usual case, two named hosts and hosts are on different switches
			net_sheep.Baa( 1, "path[%d]: searching for path starting from switch: %s", plidx, ssw.To_str( ) )

			for sname := range n.switches {					// initialise the network for the walk
				n.switches[sname].Cost = 2147483647			// this should be large enough and allows cost to be int32
				n.switches[sname].Prev = nil
				n.switches[sname].Flags &= ^tegu.SWFL_VISITED
			}

			ssw.Cost = 0												// seed the cost in the source switch

			tsw = ssw.Path_to( h2nm, commence, conclude, inc_cap )		// discover the shortest path to terminating switch that has enough bandwidth
			if tsw != nil {
				path = gizmos.Mk_path( h1, h2 )
				path.Set_reverse( true )								// indicate that the path is saved in reverse order 
				path.Set_extip( extip )
				net_sheep.Baa( 2,  "path[%d]: found target on %s", plidx, tsw.To_str( ) )
				
				lnk = n.find_vlink( *(tsw.Get_id()), h2.Get_port( tsw ), -1 )		// add endpoint -- a virtual link out from switch to h2
				lnk.Add_lbp( *h2nm )
				lnk.Set_forward( tsw )												// endpoints have only a forward link
				path.Add_endpoint( lnk )

				for ; tsw != nil ; {
					if tsw.Prev != nil {								// last node won't have a prev pointer so no link
						lnk = tsw.Prev.Get_link( tsw.Plink )
						path.Add_link( lnk )
					}	
					path.Add_switch( tsw )

					net_sheep.Baa( 2, "\t%s using link %d", tsw.Prev.To_str(), tsw.Plink )

					if tsw.Prev == nil {													// last switch in the path, add endpoint 
						lnk = n.find_vlink( *(tsw.Get_id()), h1.Get_port( tsw ), -1 )		// endpoint is a virt link from switch to h1
						lnk.Add_lbp( *h1nm )
						lnk.Set_forward( tsw )												// endpoints have only a forward link
						path.Add_endpoint( lnk )
					}
					tsw = tsw.Prev
				}

				path.Flip_endpoints()		// path expects them to be in h1,h2 order; we added them backwards so must flip
				path_list[plidx] = path
				plidx++

			} /* else {				// debug only
				net_sheep.Baa( 1,  "path[%d]: did not find a path from %s -> %s using starting switch %s", plidx, *h1nm, *h2nm, ssw.To_str( ))
			}
			*/
		}
	}

	pcount = plidx			// shouldn't get here, but safety first
	return
}

/*
	Find all paths that are associated with the reservation.  This splits the h1->h2 request into 
	two paths if h1 and h2 are in different tenants.  The resulting paths in this case are between h1 and 
	the gateway, and from the gateway to h2 (to preserve the h1->h2 directional signficance which is 
	needed if inbound and outbound rates differ.  In order to build a good set of flow-mods for the split
	reservation, both VMs MUST have an associated floating point address which is then generated as a 
	match point in the flow-mod.  
*/
func (n *Network) build_paths( h1nm *string, h2nm *string, commence int64, conclude int64, inc_cap int64 ) ( pcount int, path_list []*gizmos.Path ) {
	var (
		num int = 0				// must declare num as := assignment doesnt work when ipath[n] is in the list
	)

	path_list = nil
	if n == nil { return }

	pair_list := n.find_endpoints( h1nm, h2nm )					// determine endpoints based on names that might have different tenants
	if pair_list == nil {										// likely no fip for one or the other VMs
		return
	}

	total_paths := 0
	ok_count := 0 
	ipaths := make( [][]*gizmos.Path, len( pair_list ) )			// temp holder of each path list resulting from pair_list exploration

	for i := range pair_list {
		num, ipaths[i] = n.find_path( pair_list[i].h1, pair_list[i].h2, commence, conclude, inc_cap, pair_list[i].fip )	
		if num > 0 {
			total_paths += num
			ok_count++
		}
	}

	if ok_count < len( pair_list ) {			// didn't find a good path for each pair
		net_sheep.Baa( 1, "did not find a good path for each pair; expected %d, found %d", len( pair_list ), ok_count )
		pcount = 0
		return 
	}

	if len( ipaths ) == 1 {
		path_list = ipaths[0]
		pcount = len( ipaths[0] )
	} else {
		path_list = make( []*gizmos.Path,  total_paths )
		pcount = 0
		for i := range ipaths {
			for j := range ipaths[i] {
				path_list[pcount] = ipaths[i][j]
				pcount++
			}
		}
	}

	return
}

// --------------------  info exchange/debugging  -----------------------------------------------------------------------------------------

/*
	Generate a json list of hosts which includes ip, name, switch(es) and port(s).
*/
func (n *Network) host_list( ) ( jstr string ) {
	var( 	
		sep 	string = ""
		hname	string = ""
		seen	map[string]bool
	)

	seen = make( map[string]bool )
	jstr = ` [ `						// an array of objects

	if n != nil && n.hosts != nil {
		for _, h := range n.hosts {
			ip4, ip6 := h.Get_addresses()
			mac :=  h.Get_mac()						// track on this as we will always see this

			if seen[*mac] == false {
				seen[*mac] = true;					// we track hosts by both mac and ip so only show once

				if n.ip2vm[*ip4] != nil {
					hname = *n.ip2vm[*ip4]
				} else {
					hname = "unknown"
				}
				jstr += fmt.Sprintf( `%s { "name": %q, "mac": %q, "ip4": %q, "ip6": %q `, sep, hname, *(h.Get_mac()), *ip4, *ip6 )
				if nconns := h.Get_nconns(); nconns > 0 {
					jstr += `, "conns": [`
					sep = ""
					for i := 0; i < nconns; i++ {
						sw, port := h.Get_switch_port( i )
						if sw == nil {
							break
						}

						jstr += fmt.Sprintf( `%s { "switch": %q, "port": %d }`, sep, *(sw.Get_id( )), port )
						sep = ","
					}

					jstr += ` ]`
				}

				jstr += ` }`						// end of this host

				sep = ","
			}
		}
	} else {
		net_sheep.Baa( 0, "ERR: host_list: n is nil (%v) or n.hosts is nil", n == nil )
	}

	jstr += ` ]`			// end of hosts array

	return
}


/*
	Generate a json representation of the network graph.
*/
func (n *Network) to_json( ) ( jstr string ) {
	var	sep string = ""

	jstr = `{ "netele": [ `

	for k := range n.switches {
		jstr += fmt.Sprintf( "%s%s", sep, n.switches[k].To_json( ) )
		sep = ","
	}

	jstr += "] }"

	return
}

// --------- public -------------------------------------------------------------------------------------------

/*
	to be executed as a go routine. 
	nch is the channel we are expected to listen on for api requests etc.
	sdn_host is the host name and port number where the sdn controller is running.
	(for now we assume the sdn-host is a floodlight host and invoke FL_ to build our graph)
*/
func Network_mgr( nch chan *ipc.Chmsg, sdn_host *string ) {
	var (
		act_net *Network
		req		*ipc.Chmsg
		max_link_cap	int64 = 0
		refresh	int = 30

		pcount	int
		path_list	[]*gizmos.Path
		ip2		*string
	)

	if *sdn_host  == "" {
		sdn_host = cfg_data["default"]["sdn_host"] 
		if sdn_host == nil {
			sdn_host = cfg_data["default"]["static_phys_graph"] 
			if sdn_host == nil {
				sdn_host = &default_sdn;
				net_sheep.Baa( 1, "WRN: using default openflow host: %s", sdn_host )
			} else {
				net_sheep.Baa( 1, "WRN: using static map of physical network and openstack VM lists to build the network graph" )
			}
		}
	}

	net_sheep = bleater.Mk_bleater( 0, os.Stderr )		// allocate our bleater and attach it to the master
	net_sheep.Set_prefix( "netmgr" )
	tegu_sheep.Add_child( net_sheep )					// we become a child so that if the master vol is adjusted we'll react too

														// suss out config settings from our section
	if p := cfg_data["network"]["refresh"]; p != nil {
		refresh = clike.Atoi( *p ); 			
	}
	if p := cfg_data["network"]["link_max_cap"]; p != nil {
		max_link_cap = clike.Atoi64( *p )
	}
	if p := cfg_data["network"]["verbose"]; p != nil {
		net_sheep.Set_level(  uint( clike.Atoi( *p ) ) )
	}

														// enforce some sanity on config file settings
	if refresh <= 15 {
		net_sheep.Baa( 0, "WRN: refresh rate in config file (%d) was too small; set to 15s", refresh )
		refresh = 15
	}
	if max_link_cap <= 0 {
		max_link_cap = 1024 * 1024 * 1024 * 10							// if not in config file use 10Gbps
	}

	net_sheep.Baa( 1,  "network_mgr thread started: sdn_hpst=%s max_link_cap=%d refresh=%d", *sdn_host, max_link_cap, refresh )

	act_net = build( nil, sdn_host, max_link_cap )					// initial build of network graph; blocks and we don't enter loop until done (main depends on that)
	if act_net == nil {
		net_sheep.Baa( 0, "ERR: initial build of network failed -- core dump likely to follow!" )		// this is bad and WILL cause a core dump
	} else {
		net_sheep.Baa( 1, "initial network graph has been built" )
	}

	if refresh <= 10 {
		net_sheep.Baa( 0,  "default network refresh (30s) used because config value missing or invalid" )
		refresh = 30
	}
	tklr.Add_spot( int64( refresh ), nch, REQ_NETUPDATE, nil, ipc.FOREVER )		// add tickle spot to drive rebuild of network 
	
	for {
		select {					// assume we might have multiple channels in future
			case req = <- nch:
				req.State = nil				// nil state is OK, no error

				net_sheep.Baa( 3, "processing request %d", req.Msg_type )			// we seem to wedge in network, this will be chatty, but may help
				switch req.Msg_type {
					case REQ_NOOP:			// just ignore -- acts like a ping if there is a return channel

					case REQ_STATE:
							state := 0
							if act_net.vm2ip != nil  && act_net.ip2vm != nil { 		// non q-lite oriented things 
								state = 1
							}
							if act_net.vmid2ip != nil  && 						
									act_net.ip2vmid != nil  && 
									act_net.vmid2phost	 != nil  && 
									act_net.ip2mac != nil  && 
									act_net.mac2phost != nil  && 
									act_net.gwmap != nil  && 
									act_net.fip2ip != nil  && 
									act_net.ip2fip != nil  {
								state = 2
							}
net_sheep.Baa( 1, "STATE: %v| %v| %v| %v| %v| %v| %v == %d", act_net.vmid2ip != nil  , act_net.ip2vmid != nil  , act_net.vmid2phost	 != nil  , act_net.ip2mac != nil  , act_net.mac2phost != nil  , act_net.gwmap != nil  , act_net.fip2ip != nil, state  )
							req.Response_data = state

					case REQ_HASCAP:						// verify that there is capacity, and return the path, but don't allocate the path
						p := req.Req_data.( *gizmos.Pledge )
						h1, h2, commence, expiry, bandw_in, bandw_out := p.Get_values( )
						net_sheep.Baa( 1,  "has-capacity request received on channel  %s -> %s", h1, h2 )
						//pcount, path_list = act_net.find_path( h1, h2, commence, expiry, bandw_in + bandw_out ); 
						pcount, path_list = act_net.build_paths( h1, h2, commence, expiry, bandw_in + bandw_out ); 

						if pcount > 0 {
							req.Response_data = path_list[:pcount]
							req.State = nil
						} else {
							req.Response_data = nil
							req.State = fmt.Errorf( "unable to generate a path; no capacity or no path" )
						}

					case REQ_RESERVE:
						p := req.Req_data.( *gizmos.Pledge )
						h1, h2, commence, expiry, bandw_in, bandw_out := p.Get_values( )
						net_sheep.Baa( 1,  "network: reservation request received: %s -> %s  from %d to %d", *h1, *h2, commence, expiry )

						ip1, err := act_net.name2ip( h1 )
						ip2 = nil
						if err == nil {
							ip2, err = act_net.name2ip( h2 )
						}

						if err == nil {
							net_sheep.Baa( 2,  "network: attempt to find path between  %s -> %s", *ip1, *ip2 )
							//pcount, path_list = act_net.find_path( ip1, ip2, commence, expiry, bandw_in + bandw_out ); 
							pcount, path_list = act_net.build_paths( ip1, ip2, commence, expiry, bandw_in + bandw_out ); 

							if pcount > 0 {
								net_sheep.Baa( 1,  "network: acceptable path found:" )

								qid := p.Get_id()
								p.Set_qid( qid )					// add the queue id to the pledge

								for i := 0; i < pcount; i++ {		// set the queues for each path in the list (multiple paths if network is disjoint)
									net_sheep.Baa( 2,  "\tpath_list[%d]: %s -> %s\n\t%s", i, *h1, *h2, path_list[i].To_str( ) )
									path_list[i].Set_queue( qid, commence, expiry, bandw_in, bandw_out )		// this causes the utilisation to be increased; no explicit Inc_util is needed
								}

								req.Response_data = path_list[:pcount]
								req.State = nil
							} else {
								req.Response_data = nil
								req.State = fmt.Errorf( "unable to generate a path; no capacity or no path" )
								net_sheep.Baa( 0,  "WRN: network: no path count %s", req.State )
							}
						} else {
							net_sheep.Baa( 0,  "WRN: network: unable to map to an IP address: %s",  err )
							req.State = fmt.Errorf( "unable to map host name to a known IP address: %s", err )
						}



					case REQ_DEL:							// delete the utilisation for the given reservation
						net_sheep.Baa( 1,  "network: deleting reservation" )
						p := req.Req_data.( *gizmos.Pledge )
						_, _, commence, expiry, bandw_in, bandw_out := p.Get_values( )
						pl := p.Get_path_list( )
						pcount := len( pl )

						for i := 0; i < pcount; i++ {
							net_sheep.Baa( 1,  "network: deleting path %d", i )
							path_list[i].Inc_utilisation( commence, expiry, -(bandw_in + bandw_out) )
						}

					case REQ_VM2IP:								// a new vm name/vm ID to ip address map 
						if req.Req_data != nil {
							act_net.vm2ip = req.Req_data.( map[string]*string )
							act_net.ip2vm = act_net.build_ip2vm( )
							net_sheep.Baa( 2, "vm2ip and ip2vm maps were updated, has %d entries", len( act_net.vm2ip ) )
						} else {
							net_sheep.Baa( 1, "vm2ip map was nil; not changed" )
						}


					case REQ_VMID2IP:									// Tegu-lite
						if req.Req_data != nil {
							act_net.vmid2ip = req.Req_data.( map[string]*string )
						} else {
							net_sheep.Baa( 1, "vmid2ip map was nil; not changed" )
						}

					case REQ_IP2VMID:									// Tegu-lite
						if req.Req_data != nil {
							act_net.ip2vmid = req.Req_data.( map[string]*string )
						} else {
							net_sheep.Baa( 1, "ip2vmid map was nil; not changed" )
						}

					case REQ_VMID2PHOST:									// Tegu-lite
						if req.Req_data != nil {
							act_net.vmid2phost = req.Req_data.( map[string]*string )
						} else {
							net_sheep.Baa( 1, "vmid2phost map was nil; not changed" )
						}

					case REQ_IP2MAC:									// Tegu-lite
						if req.Req_data != nil {
							act_net.ip2mac = req.Req_data.( map[string]*string )
						} else {
							net_sheep.Baa( 1, "ip2mac map was nil; not changed" )
						}

					case REQ_GWMAP:									// Tegu-lite
						if req.Req_data != nil {
							act_net.gwmap = req.Req_data.( map[string]*string )
						} else {
							net_sheep.Baa( 1, "ip2mac map was nil; not changed" )
						}

					case REQ_IP2FIP:									// Tegu-lite
						if req.Req_data != nil {
							act_net.ip2fip = req.Req_data.( map[string]*string )
						} else {
							net_sheep.Baa( 1, "ip2fip map was nil; not changed" )
						}

					case REQ_FIP2IP:
						if req.Req_data != nil {
							act_net.fip2ip = req.Req_data.( map[string]*string )
						} else {
							net_sheep.Baa( 1, "fip2ip map was nil; not changed" )
						}


					case REQ_GEN_QMAP:							// generate a new queue setting map
						ts := req.Req_data.( int64 )			// time stamp for generation
						req.Response_data, req.State = act_net.gen_queue_map( ts, false )

					case REQ_GEN_EPQMAP:						// generate a new queue setting map but only for endpoints
						ts := req.Req_data.( int64 )			// time stamp for generation
						req.Response_data, req.State = act_net.gen_queue_map( ts, true )
						
					case REQ_GETIP:								// given a VM name or ID return the IP if we know it. 
						s := req.Req_data.( string )
						req.Response_data, req.State = act_net.name2ip( &s )		// returns ip or nil

					case REQ_GETLMAX:							// DEPRECATED!  request for the max link allocation
						req.Response_data = nil;
						req.State = nil;

					case REQ_NETUPDATE:								// build a new network graph
						net_sheep.Baa( 2, "rebuilding network graph" )
						new_net := build( act_net, sdn_host, max_link_cap )
						if new_net != nil {
							vm2ip_map := act_net.vm2ip					// these don't come with the new graph; save old and add back 
							ip2vm_map := act_net.ip2vm
							vmid2ip_map := act_net.vmid2ip
							ip2vmid_map := act_net.ip2vmid
							vmid2phost_map := act_net.vmid2phost	
							ip2mac_map := act_net.ip2mac
							mac2phost := act_net.mac2phost
							gwmap := act_net.gwmap
							fip2ip := act_net.fip2ip
							ip2fip := act_net.ip2fip

							act_net = new_net

							act_net.vm2ip = vm2ip_map					// and put them back into the new one
							act_net.ip2vm = ip2vm_map
							act_net.vmid2ip = vmid2ip_map 
							act_net.ip2vmid = ip2vmid_map 
							act_net.vmid2phost	 = vmid2phost_map
							act_net.ip2mac = ip2mac_map
							act_net.mac2phost = mac2phost
							act_net.gwmap = gwmap
							act_net.fip2ip = fip2ip
							act_net.ip2fip = ip2fip

							net_sheep.Baa( 1, "network graph rebuild completed" )		// timing during debugging
						} else {
							net_sheep.Baa( 1, "unable to update network graph -- SDNC down?" )
						}

						
					//	------------------ user api things ---------------------------------------------------------
					case REQ_NETGRAPH:							// dump the current network graph
						req.Response_data = act_net.to_json()

					case REQ_HOSTLIST:							// json list of hosts with name, ip, switch id and port
						req.Response_data = act_net.host_list( )

					case REQ_LISTCONNS:							// for a given host spit out the switch(es) and port(s) 
						hname := req.Req_data.( *string )
						host := act_net.hosts[*hname]
						if host != nil {
							req.Response_data = host.Ports2json( ); 
						} else {
							req.Response_data = nil			// assume failure
							req.State = fmt.Errorf( "did not find host: %s", *hname )

							net_sheep.Baa( 2, "looking up name for listconns: %s", *hname )
							hname = act_net.vm2ip[*hname]		// maybe they sent a vm ID or name
							if hname == nil || *hname == "" {
								net_sheep.Baa( 2, "unable to find name in vm2ip table" )

								if net_sheep.Get_level() > 2 {
									for k, v := range act_net.vm2ip {
										net_sheep.Baa( 3, "vm2ip[%s] = %s", k, *v );
									}
								}
							} else {
								net_sheep.Baa( 2, "name found in vm2ip table translated to: %s, looking up  host", *hname )
								host = act_net.hosts[*hname]
								if host != nil {
									req.Response_data = host.Ports2json( ); 
									req.State = nil
								} else {
									net_sheep.Baa( 2, "unable to find host entry for: %s", *hname )
								}
							}
						}

					// --------------------- agent things -------------------------------------------------------------
					case REQ_MAC2PHOST:
						req.Response_ch = nil			// we don't respond to these
						act_net.update_mac2phost(  req.Req_data.( []string ) )

					default:
						net_sheep.Baa( 1,  "unknown request received on channel: %d", req.Msg_type )
				}

				net_sheep.Baa( 3, "processing request complete %d", req.Msg_type )
				if req.Response_ch != nil {				// if response needed; send the request (updated) back 
					req.Response_ch <- req
				}

		}
	}
}

